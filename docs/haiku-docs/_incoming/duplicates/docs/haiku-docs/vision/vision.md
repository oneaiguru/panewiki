<!-- model: opus -->
# Why This Matters: The Paradigm Shift

## The Fundamental Problem

**Current AI interfaces violate human cognition:**

```
AI Output:    10,000 tokens (complete)
Human Brain:  100 tokens (processing window)
Result:       9,900 tokens never read
```

Users don't read walls of text. They skim first, decide relevance, then drill.

But AI tools deliver complete content upfront. Mismatch = information overload.

## Three Critical Insights

### 1. Information Architecture Matters More Than Content

```
OLD: "Here's everything" (10,000 tokens)
     User: Lost. Overwhelmed. Leaves.

NEW: "Here's essence" (100 tokens)
     User: Understands direction
     → Clicks for details as needed
     → Engages deeper → reads MORE total
```

**Paradox:** Showing LESS initially makes users read MORE overall.

### 2. Reading Width Affects Comprehension

Decades of newspaper + web research prove:
- 80+ char lines: eye strain, comprehension -15%
- 60-75 char lines: optimal, comprehension +20%
- Too narrow: awkward wrapping, engagement down

**400px column = 60-75 characters = optimal reading.**

It's not aesthetic. It's cognitive science.

### 3. Not All AI Work Costs The Same

```
Opus:  $15/M tokens  (Strategic thinking)
Haiku: $0.80/M tokens (Execution)
       18.75× difference

Using Opus for everything = paying $1 for $0.05 work.
```

**Smart orchestration:** Opus thinks (once, expensive), Haiku executes (parallel, cheap), Sonnet validates (moderate, reliable).

Result: 87% cost reduction + BETTER quality.

## The Paradigm Shift

```
FROM: Linear scrolling          TO: Layered navigation
  ↓ One model                       ↓ Three models
  ↓ One pass                        ↓ Multi-pass verification
  ↓ Complete output                 ↓ Summary → Detail on demand
  ↓ Users overwhelmed               ↓ Users engaged + informed
```

## Why Now?

1. **LLM pricing enables it** - Cheap models for execution (2024)
2. **Token budgets matter** - Every token = real cost
3. **Cognitive load is real** - Brain hasn't changed
4. **Parallel execution works** - Generate multiple components simultaneously
5. **Transparency teaches** - Users learn optimal AI patterns

## What Changes

✓ Users see essence first (30 lines) not everything (10,000 lines)
✓ Architects think in layers (summary, detail) not linear flows
✓ Developers use 3 models (each for their strength) not 1 for all
✓ Teams save 87% on API costs while improving quality
✓ Learning curve becomes interface teaching tool

---

**Deep dive:** [Problem Statement](problem-statement) | **Learn:** [How Columns Work](../three-pillars/pillar-1/pillar-1-column-output) | **See cost savings:** [Token Economics](../architecture/token-economics)
